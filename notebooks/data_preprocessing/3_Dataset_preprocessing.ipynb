{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-25 13:25:33.867018: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-25 13:25:35.364446: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import h5py\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_path = os.path.expanduser('~')\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "working_path = os.path.join(parent_dir) #incase directory needs to be expanded\n",
    "downloads_path = os.path.join(home_path, 'Downloads')\n",
    "#extract_dir = os.path.expanduser(\"~\\\\Data_science\")\n",
    "extract_dir = os.path.join(home_path, 'Nextcloud/DataScientest/project/pcb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up folder paths\n",
    "# Define the source paths for images and annotations\n",
    "image_pool_path = os.path.join(extract_dir, 'VOC_PCB', 'JPEGImages')\n",
    "annot_pool_path = os.path.join(extract_dir, 'VOC_PCB', 'Annotations')\n",
    "\n",
    "# Define the destination path for images and annotations\n",
    "image_dest_path = os.path.join(working_path, 'data', 'Images')\n",
    "annot_dest_path = os.path.join(working_path, 'data', 'Annotations')\n",
    "\n",
    "# Define the destination path for bboxes and masks\n",
    "bb_path = os.path.join(working_path, 'data', 'Images_bb')\n",
    "mask_path = os.path.join(working_path, 'data', 'Pixel_masks')\n",
    "\n",
    "# Define the destination path for csv file\n",
    "csv_path = os.path.join(working_path, 'data', 'csv')\n",
    "\n",
    "image_dataset_path = image_dest_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv_bounding_boxes = (f'{csv_path}\\\\PCB_annotations_dataset.csv')\n",
    "csv_bounding_boxes = os.path.join(csv_path, 'PCB_annotations_dataset.csv')\n",
    "images = os.listdir(image_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_bounding_boxes, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounding_boxes_data = pd.read_csv(csv_bounding_boxes, sep=\";\")\n",
    "\n",
    "image_data = []\n",
    "class_labels = []\n",
    "mask_data= []\n",
    "\n",
    "grouped_bbox = bounding_boxes_data.groupby('filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = []\n",
    "mask_data = []\n",
    "class_labels = []\n",
    "\n",
    "for filename in images:\n",
    "   \n",
    "    image_path = os.path.join(image_dataset_path, filename)\n",
    "    \n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (600, 600))  \n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image_array = np.asarray(gray_image) / 255.0 \n",
    "    image_data.append(image_array)\n",
    "\n",
    "    filename = os.path.splitext(filename)[0]\n",
    "        \n",
    "    mask = np.zeros((600, 600), dtype=np.uint8)\n",
    "\n",
    "    if filename in grouped_bbox.groups:\n",
    "        image_bbox_df = grouped_bbox.get_group(filename)\n",
    "\n",
    "        for index, row in image_bbox_df.iterrows():\n",
    "            class_label = row['defect']\n",
    "        \n",
    "            xmin, ymin, xmax, ymax = [int(row['xmin']), int(row['ymin']), int(row['xmax']), int(row['ymax'])] \n",
    "            #mask_color = class_to_color[class_label]\n",
    "            mask[ymin:ymax, xmin:xmax] = 1 #mask_color \n",
    "    \n",
    "        \n",
    "    mask_data.append(mask)\n",
    "    \n",
    "    class_labels.append(class_label)\n",
    "\n",
    "X_images = np.array(image_data)\n",
    "y_bounding_boxes = np.array(mask_data)\n",
    "y_class_labels = np.array(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 600, 600)\n",
      "(600, 600, 600)\n",
      "(600,)\n"
     ]
    }
   ],
   "source": [
    "print(X_images.shape)\n",
    "print(y_bounding_boxes.shape)\n",
    "print(y_class_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: missing_hole, Count: 100\n",
      "Label: mouse_bite, Count: 100\n",
      "Label: open_circuit, Count: 100\n",
      "Label: short, Count: 100\n",
      "Label: spur, Count: 100\n",
      "Label: spurious_copper, Count: 100\n"
     ]
    }
   ],
   "source": [
    "unique_labels, label_counts = np.unique(y_class_labels, return_counts=True)\n",
    "\n",
    "for label, count in zip(unique_labels, label_counts):\n",
    "    print(f\"Label: {label}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21600, 100, 100)\n",
      "(21600, 100, 100)\n",
      "(21600,)\n"
     ]
    }
   ],
   "source": [
    "new_size = (100, 100)\n",
    "threshold_none = 5\n",
    "def crop_images(X_images, y_bounding_boxes, y_class_labels, new_size):\n",
    "    if not all(new < orig and orig % new == 0 for orig, new in zip((600, 600), new_size)):\n",
    "        print(\"New size must be smaller and a divisor of the original size.\")\n",
    "        return False\n",
    "    \n",
    "    cropped_images_int = []\n",
    "    cropped_masks_int = []\n",
    "    cropped_y_class_labels_int = []\n",
    "\n",
    "    for image, mask, labels in zip(X_images, y_bounding_boxes, y_class_labels):\n",
    "        for y in range(0, 600, new_size[0]):\n",
    "            for x in range(0, 600, new_size[0]):\n",
    "                y0, x0 = y, x\n",
    "                y_new_size, x_new_size = y+new_size[0], x+new_size[0]\n",
    "                # if a bounding box crosses the cropping border, shift the corresponding border, so defects are not cut off\n",
    "                while( np.any(mask[y0, x0:x_new_size])) and (y0 != 0): \n",
    "                    y0 -= 1\n",
    "                while (np.any(mask[min(y_new_size, 599), x0:x_new_size])) and (y_new_size != 600):\n",
    "                    y_new_size += 1\n",
    "                while( np.any(mask[y0:y_new_size, x0])) and (x0 != 0):\n",
    "                    x0 -= 1\n",
    "                while( np.any(mask[y0:y_new_size, min(x_new_size, 599)])) and (x_new_size != 600):\n",
    "                    x_new_size += 1\n",
    "                patch_image = cv2.resize(image[y0:y_new_size, x0:x_new_size], new_size)\n",
    "                patch_mask = cv2.resize(mask[y0:y_new_size, x0:x_new_size], new_size)\n",
    "                \n",
    "                #patch_image = image[y:y+new_size[0], x:x+new_size[0]]\n",
    "                #patch_mask = mask[y:y+new_size[0], x:x+new_size[0]]\n",
    "\n",
    "                if np.sum(patch_mask) > threshold_none:\n",
    "                    cropped_images_int.append(patch_image)\n",
    "                    cropped_masks_int.append(patch_mask)\n",
    "                    cropped_y_class_labels_int.append(labels)\n",
    "                else:\n",
    "                    cropped_images_int.append(patch_image)\n",
    "                    cropped_masks_int.append(patch_mask)\n",
    "                    cropped_y_class_labels_int.append(\"none\")\n",
    "\n",
    "    cropped_images = np.array(cropped_images_int)\n",
    "    cropped_masks = np.array(cropped_masks_int)\n",
    "    cropped_y_class_labels = np.array(cropped_y_class_labels_int)\n",
    "    return cropped_images, cropped_masks, cropped_y_class_labels\n",
    "\n",
    "cropped_images, cropped_masks, cropped_y_class_labels = crop_images(X_images, y_bounding_boxes, y_class_labels, new_size)\n",
    "\n",
    "print(cropped_images.shape)\n",
    "print(cropped_masks.shape)\n",
    "print(cropped_y_class_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: missing_hole, Count: 329\n",
      "Label: mouse_bite, Count: 294\n",
      "Label: none, Count: 19644\n",
      "Label: open_circuit, Count: 292\n",
      "Label: short, Count: 358\n",
      "Label: spur, Count: 365\n",
      "Label: spurious_copper, Count: 318\n"
     ]
    }
   ],
   "source": [
    "unique_labels, label_counts = np.unique(cropped_y_class_labels, return_counts=True)\n",
    "\n",
    "for label, count in zip(unique_labels, label_counts):\n",
    "    print(f\"Label: {label}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, masks, labels, num_samples=6):\n",
    "    _ , axes = plt.subplots(2, 3, figsize=(10, 6))\n",
    "    axes = axes.ravel()\n",
    "    sample_indices = np.random.choice(len(images), num_samples, replace=False)\n",
    "    \n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        axes[i].imshow(images[idx], cmap='gray')\n",
    "        axes[i].imshow(masks[idx], alpha=0.5, cmap='jet')\n",
    "        axes[i].set_title(f'Label: {labels[idx]}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot random 6 images\n",
    "plot_images(cropped_images, cropped_masks, cropped_y_class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def separate_defects(original_images, mask_images, class_labels):\n",
    "    separated_images = []\n",
    "    separated_masks = []\n",
    "    separated_labels = []\n",
    "\n",
    "    for idx, (original_image, mask_image, class_label) in enumerate(zip(original_images, mask_images, class_labels)):\n",
    "        contours, _ = cv2.findContours(mask_image.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        # print(f\"Processing Image {idx+1}\")\n",
    "        # print(f\"Found {len(contours)} contours in image {idx+1}\")\n",
    "        if len(contours) > 1:\n",
    "            #print(f\"Image {idx+1}: Found {len(contours)} contours.\")\n",
    "            for _, contour in enumerate(contours):\n",
    "                # print(f\"Processing Contour {contour_idx+1} of {len(contours)}\")\n",
    "                all_contours_mask = np.zeros_like(mask_image)\n",
    "                cv2.drawContours(all_contours_mask, [contour], -1, 255, -1)\n",
    "\n",
    "                exclude_other_contours_mask = np.zeros_like(mask_image)\n",
    "                cv2.drawContours(exclude_other_contours_mask, contours, -1, 255, -1)\n",
    "                exclude_other_contours_mask = cv2.bitwise_xor(all_contours_mask, exclude_other_contours_mask)\n",
    "\n",
    "                new_image = original_image.copy()\n",
    "                new_mask = mask_image.copy()\n",
    "\n",
    "                new_image[exclude_other_contours_mask == 255] = 0\n",
    "                new_mask[exclude_other_contours_mask == 255] = 0\n",
    "\n",
    "                separated_images.append(new_image)\n",
    "                separated_masks.append(new_mask)\n",
    "                separated_labels.append(class_label)\n",
    "\n",
    "                '''\n",
    "                # Debug print to confirm the processing of each contour\n",
    "                print(f\"Processed contour {contour_idx+1} for image {idx+1}\")\n",
    "                plt.figure(figsize=(8, 4))\n",
    "                plt.subplot(1, 2, 1)\n",
    "                plt.imshow(new_image, cmap='gray')\n",
    "                plt.title(f\"Image {idx+1} Contour {contour_idx+1}\")\n",
    "                plt.subplot(1, 2, 2)\n",
    "                plt.imshow(new_mask, cmap='gray')\n",
    "                plt.title(f\"Mask {idx+1} Contour {contour_idx+1}\")\n",
    "                plt.show()\n",
    "                '''\n",
    "\n",
    "        else:\n",
    "            separated_images.append(original_image.copy())\n",
    "            separated_masks.append(mask_image.copy())\n",
    "            separated_labels.append(class_label)\n",
    "            # print(f\"Image {idx+1} has {len(contours)} contours, appending original.\")\n",
    "                                        \n",
    "    return separated_images, separated_masks, separated_labels\n",
    "\n",
    "separated_images, separated_masks, separated_labels = separate_defects(cropped_images, cropped_masks, cropped_y_class_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21626, 100, 100)\n",
      "(21626, 100, 100)\n",
      "(21626,)\n"
     ]
    }
   ],
   "source": [
    "separated_images_array = np.asarray(separated_images)\n",
    "separated_masks_array = np.asarray(separated_masks)\n",
    "separated_labels_array = np.asarray(separated_labels)\n",
    "\n",
    "print(separated_images_array.shape)\n",
    "print(separated_masks_array.shape)\n",
    "print(separated_labels_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if separated_images:\n",
    "    plot_images(separated_images_array, separated_masks_array, separated_labels_array)\n",
    "else:\n",
    "    print(\"No separated images found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: missing_hole, Count: 332\n",
      "Label: mouse_bite, Count: 295\n",
      "Label: none, Count: 19644\n",
      "Label: open_circuit, Count: 298\n",
      "Label: short, Count: 361\n",
      "Label: spur, Count: 369\n",
      "Label: spurious_copper, Count: 327\n"
     ]
    }
   ],
   "source": [
    "unique_labels, label_counts = np.unique(separated_labels, return_counts=True)\n",
    "label_count_dict = defaultdict(int)\n",
    "\n",
    "for label, count in zip(unique_labels, label_counts):\n",
    "    label_count_dict[label] = count\n",
    "    print(f\"Label: {label}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 5))\n",
    "plt.bar(unique_labels, label_counts, color='skyblue')\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Labels')\n",
    "plt.xticks(rotation=45) \n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above distribution of data is clearly unbalanced, so we need to balance out the data by introducing more images to even out the distribution or to delete some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_samples_per_class = min(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out extra samples for each class label\n",
    "filtered_images = []\n",
    "filtered_masks = []\n",
    "filtered_labels = []\n",
    "\n",
    "for label in unique_labels:\n",
    "    label_indices = [i for i, l in enumerate(separated_labels_array) if l == label]\n",
    "    if label_count_dict[label] > max_samples_per_class:\n",
    "        selected_indices = np.random.choice(label_indices, max_samples_per_class, replace=False)\n",
    "    else:\n",
    "        selected_indices = label_indices\n",
    "    filtered_images.extend(separated_images_array[selected_indices])\n",
    "    filtered_masks.extend(separated_masks_array[selected_indices])\n",
    "    filtered_labels.extend(separated_labels_array[selected_indices])\n",
    "\n",
    "# Convert the filtered lists to arrays\n",
    "filtered_images = np.array(filtered_images)\n",
    "filtered_masks = np.array(filtered_masks)\n",
    "filtered_labels = np.array(filtered_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Images Shape: (2065, 100, 100)\n",
      "Filtered Masks Shape: (2065, 100, 100)\n",
      "Filtered Labels Shape: (2065,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of filtered data\n",
    "print(\"Filtered Images Shape:\", filtered_images.shape)\n",
    "print(\"Filtered Masks Shape:\", filtered_masks.shape)\n",
    "print(\"Filtered Labels Shape:\", filtered_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: missing_hole, Count: 295\n",
      "Label: mouse_bite, Count: 295\n",
      "Label: none, Count: 295\n",
      "Label: open_circuit, Count: 295\n",
      "Label: short, Count: 295\n",
      "Label: spur, Count: 295\n",
      "Label: spurious_copper, Count: 295\n"
     ]
    }
   ],
   "source": [
    "filtered_unique_labels, filtered_label_counts = np.unique(filtered_labels, return_counts=True)\n",
    "\n",
    "label_count_dict = defaultdict(int)\n",
    "\n",
    "for label, count in zip(filtered_unique_labels, filtered_label_counts):\n",
    "    label_count_dict[label] = count\n",
    "    print(f\"Label: {label}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After including more images (along with the coresponding masks and labels) and deleting surplus data, the dataset is more balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, label in enumerate(filtered_labels):\n",
    "    # Check if the label is \"none\"\n",
    "    if label == \"none\":\n",
    "        # Replace the corresponding mask image with a blank image\n",
    "        filtered_masks[i] = np.zeros_like(filtered_masks[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "y_class_labels_encoded = encoder.fit_transform(filtered_labels)\n",
    "filtered_y_categorical = to_categorical(y_class_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = []\n",
    "\n",
    "combined_data = list(zip(filtered_images, filtered_masks, filtered_labels, filtered_y_categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 666\n",
    "\n",
    "picks = np.random.choice(range(filtered_labels.shape[0]), 10, replace=False)\n",
    "\n",
    "for i in picks:\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10,10))\n",
    "    ax[0].imshow(filtered_images[i], cmap='gray')\n",
    "    ax[1].imshow(filtered_masks[i], cmap='gray')\n",
    "    ax[0].set_title(f'Label: {filtered_labels[i]}')\n",
    "    ax[1].set_title(f'Categorical: {filtered_y_categorical[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2065, 100, 100)\n",
      "(2065, 100, 100)\n",
      "(2065,)\n",
      "(2065, 7)\n",
      "(7,)\n"
     ]
    }
   ],
   "source": [
    "print(filtered_images.shape)\n",
    "print(filtered_masks.shape)\n",
    "print(filtered_labels.shape)\n",
    "print(filtered_y_categorical.shape)\n",
    "print(filtered_label_counts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and validation sets\n",
    "X_train, X_test, y_train_mask, y_test_mask, y_train_class, y_test_class= train_test_split(filtered_images, filtered_masks, filtered_y_categorical, \n",
    "                                                                                                      test_size=0.2, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1652, 100, 100)\n",
      "y_train_mask shape: (1652, 100, 100)\n",
      "y_train_class shape: (1652, 7)\n",
      "X_test shape: (413, 100, 100)\n",
      "y_test_mask shape: (413, 100, 100)\n",
      "y_test_class shape: (413, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train_mask shape:\", y_train_mask.shape)\n",
    "print(\"y_train_class shape:\", y_train_class.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test_mask shape:\", y_test_mask.shape)\n",
    "print(\"y_test_class shape:\", y_test_class.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save the filtered, augmented dataset to disk\n",
    "def save_data_to_disk(X, y_mask, y_class, filepath):\n",
    "    with h5py.File(filepath, 'w') as hf:\n",
    "        hf.create_dataset('X', data=X)\n",
    "        hf.create_dataset('y_mask', data=y_mask)\n",
    "        hf.create_dataset('y_class', data=y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_train = \"train_data.h5\"\n",
    "file_name_test = \"test_data.h5\"\n",
    "\n",
    "file_path_train = os.path.join(downloads_path, file_name_train)\n",
    "file_path_test = os.path.join(downloads_path, file_name_test)\n",
    "\n",
    "save_data_to_disk(X_train, y_train_mask, y_train_class, file_path_train)\n",
    "save_data_to_disk(X_test, y_test_mask, y_test_class, file_path_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pcb_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
